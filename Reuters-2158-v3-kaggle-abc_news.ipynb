{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis of ABC News.\n",
    "\n",
    "Apply the LDA model trained on Reuters.2158 against the Kaggle ABC News that all are in one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/rtaubes/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# nltk.download('reuters')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = '../dataset/kaggle/abcnews-2017-06.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters count\n",
    "LDA_MODEL = 'models/nltk_lda_cnt.pkl'\n",
    "VECTORIZER = 'models/nltk_vct_cnt.pkl'\n",
    "TOKENS = 'models/nltk_cnt.pkl'\n",
    "MIN_DOCS = 30\n",
    "# reuters ttidf\n",
    "# LDA_MODEL = 'models/nltk_lda_tfidf.pkl'\n",
    "# VECTORIZER = 'models/nltk_vct_tfidf.pkl'\n",
    "# TOKENS = 'models/nltk_token_tfidf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 16176)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(LDA_MODEL, 'rb') as mfile:\n",
    "    lda_model = pickle.load(mfile)\n",
    "with open(VECTORIZER, 'rb') as mfile:\n",
    "    vectorizer = pickle.load(mfile)\n",
    "with open(TOKENS, 'rb') as mfile:\n",
    "    train_tokens = pickle.load(mfile)\n",
    "NUM_TOPICS = lda_model.components_.shape[0]\n",
    "NUM_FEATURES = lda_model.components_.shape[1]\n",
    "NUM_TOPICS, NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>headline_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>abbott calls for special courts for returning ...</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>abductors poured flammable liquid on woman cou...</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>a day in the life of a country vet</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>adelaide shivers through coldest start to winter</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>afl scorecentre port adelaide power hawthorn h...</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                      headline_text  \\\n",
       "0   2017-06-01  abbott calls for special courts for returning ...   \n",
       "1   2017-06-01  abductors poured flammable liquid on woman cou...   \n",
       "2   2017-06-01                 a day in the life of a country vet   \n",
       "3   2017-06-01   adelaide shivers through coldest start to winter   \n",
       "4   2017-06-01  afl scorecentre port adelaide power hawthorn h...   \n",
       "\n",
       "  headline_category  \n",
       "0               any  \n",
       "1               any  \n",
       "2               any  \n",
       "3               any  \n",
       "4               any  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('headline_category', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 10 feature names:\n",
      "['---', '--i', '--will', '-agency', '-apr-', '-april', '-based', '-billion-dlr', '-billion-dlr-a-year', '-canada']\n",
      "topics in LDA model:\n",
      "Topic #0: bbl outokumpu markka wirsbo kern stripper metallverken three-week inter-city potomac\n",
      "Topic #1: mooring roy ntt gabon easter wisenbaker pitts oahu superfund decontrol\n",
      "Topic #2: bank said dollar rate pct rates market growth exchange money\n",
      "Topic #3: hungary seipp austmet mti asturiana forint shorter villages janos subsistence\n",
      "Topic #4: says baker volcker tool plywood brussels hike does kernels staple\n",
      "Topic #5: market analysts american traders stocks said analyst week high likely\n",
      "Topic #6: rice bureau lbs agriculture oats reserve bancorp portland kenya coastal\n",
      "Topic #7: daily newspaper circulation zones rebound badly publishing vietnam pigs pipe\n",
      "Topic #8: fee cane allowance province irrigation rivers transferred widespread fomc delegations\n",
      "Topic #9: greece aide devaluation aegean nearby greek wages papandreou puts reversed\n",
      "Topic #10: oil opec barrel world saudi standard prices arabia price credit\n",
      "Topic #11: ina ruding brown-forman hfag onno emphasises enourmous miniister mmct cater\n",
      "Topic #12: realty resort vms veto seasons bombing raided preservation impair unfounded\n",
      "Topic #13: said year prices production rise report gas lower output expected\n",
      "Topic #14: tankers hormuz tehran anti-ship persian installed straits regime parliamentarians superpower\n",
      "Topic #15: herrington eia residual spr mellon enacted year-to-date dubai brent mel\n",
      "Topic #16: futures taiwan trading figures products new heavy april buys year\n",
      "Topic #17: pumping majeure metres remittances repairing syeduzzaman attain dynamite chacapalca ministries\n",
      "Topic #18: nino api distillate -mar- postings degrees wti cycle phenomenon bbl\n",
      "Topic #19: february china includes feb jan dec total kong hong malaysian\n",
      "Topic #20: avg steel excludes spot und firm soybeans export inspections reforms\n",
      "Topic #21: oper kay drafting version lunch pubco geothermal geo liedtke toys\n",
      "Topic #22: seamen ohio rio michigan marines damages shipowners unrest sealy stoppage\n",
      "Topic #23: dividend loan cents tonne savings payable board association home federal\n",
      "Topic #24: gnp fields turkey turkish oil silas warships yugoslav jobless departments\n",
      "Topic #25: huckaby palladium otsuki technigen slash message moderating rocks enriched nikkeiren\n",
      "Topic #26: zambia kwacha ferry tallow prt quantity accident damaged auctions explosion\n",
      "Topic #27: purchases factors measures controls snow rules depend netherlands degree notice\n",
      "Topic #28: march div contract quarterly delivery silver ended initial qtly houston\n",
      "Topic #29: aid texaco guillaume pennzoil milk protests fitzwater goals dependency premature\n",
      "Topic #30: processors riyals separated mechanically labelling al-wattari derived mge relax correspond\n",
      "Topic #31: beef cattle follows rep approved zealand kuwait ceiling debate administration\n",
      "Topic #32: disease mcivor citrus hardly lies laying salaries axis japan-u vegetables\n",
      "Topic #33: government said official foreign economic trade domestic ministry officials budget\n",
      "Topic #34: imports west soviet marks nil german germany month union bundesbank\n",
      "Topic #35: minus certs dole bushel danish weights lag amt aides windfall\n",
      "Topic #36: trust respectively partners communications waiting certificate basic thai television delays\n",
      "Topic #37: mln profit stg year note operations current adjusted extraordinary dlr\n",
      "Topic #38: eep feedgrains colombia glickman amendments subsidized sen olein dan boschwitz\n",
      "Topic #39: units ranged interbank kuwaiti sowings durable missile quiet riyal spreads\n",
      "Topic #40: grain pacific southern feed twa santa periods union volume loading\n",
      "Topic #41: lyng offering deficiency debentures covering decoupling hrs convertible subordinated registration\n",
      "Topic #42: loss shr revs dlrs mths plaza international finland fiscal mln\n",
      "Topic #43: national committee community management bids chemlawn special offer waste war\n",
      "Topic #44: estimate payout deliveries resources petrobras meters discovered sarney fekete plunged\n",
      "Topic #45: plant union bonus workers ecuador institute energy pipeline months chrysler\n",
      "Topic #46: imf lira calm horner abolish czechoslovakia anchor pri haiti vogtle\n",
      "Topic #47: bolivia nogales bolivian annualised initiated fertilizer finnish estenssoro repaid hydro\n",
      "Topic #48: record april stock goods pay sets split consumer sterling qtly\n",
      "Topic #49: saito frustration foresees pertamina slashed iomega contents speedy eishiro haruo\n",
      "Topic #50: pct january rose dutch compared statistics months base guilders rises\n",
      "Topic #51: fund ups foster understood moratorium bands plain stimulus periodic wildlife\n",
      "Topic #52: delegates session cocoa icco origin attend crucial priority optional ghana\n",
      "Topic #53: risen uruguay stabilization constraints reluctant drawing varieties plantations calculations stabilizing\n",
      "Topic #54: tonnes said export total season figures sources india winter shipments\n",
      "Topic #55: food rains damage crops crop rainfall drought buenos aires dry\n",
      "Topic #56: wheat corn department sugar program usda week agricultural cotton sales\n",
      "Topic #57: -apr- thyssen schillings spethmann valhi taqi stahl qassem thyh steel-making\n",
      "Topic #58: cts net dlrs mln qtr year sales share prior corp\n",
      "Topic #59: pounds ascs coin exemption mint milled governors duluth este addressing\n",
      "Topic #60: cftc sweetener syrup fructose hfcs- sweeteners penalized sugarbeet westlb staying\n",
      "Topic #61: release cable restated video implement military navy rental allied-lyons lightning\n",
      "Topic #62: trade japan yen japanese countries intervention said dealers reagan prime\n",
      "Topic #63: miyazawa poehl kiichi intervening otto karl passage obstacle overshoot porsche\n",
      "Topic #64: northern yield limited western lead areas metal sea lynch merrill\n",
      "Topic #65: sumita maekawa satoshi instability leaded viermetz models rein visiting amro\n",
      "Topic #66: ppi envoy arvin aqazadeh rafsanjani arbed zverev irna gholamreza al-shaheen\n",
      "Topic #67: stores systems retail technology enhancement computer authority usage terminal scheme\n",
      "Topic #68: republicbank cam petroliferos fiscales ypf yacimientos fci spar danaher engelhard\n",
      "Topic #69: farmers soybean agriculture crop said production usda weather bushels acreage\n",
      "Topic #70: effectiveness seas alexandria shadow fluctuating kangyo schilling androsch coleman sdrs\n",
      "Topic #71: sold borg-warner changing amid jacobs confirmation champion allocation updated echlin\n",
      "Topic #72: bags sept kilos ibc conable green bonuses aug hits arrivals\n",
      "Topic #73: apr mar prev bbls jun subproducts inland jul linoil sunoil\n",
      "Topic #74: buffer quota cocoa round tin survey sanctions inra delegates itc\n",
      "Topic #75: billion dlrs deficit quarter year january surplus december trade fell\n",
      "Topic #76: amstutz unc barge pik gao ovr carrying hrw stockton peoria\n",
      "Topic #77: fat saturated differentials tropical scientists procedure nonetheless cholesterol differential chang\n",
      "Topic #78: miners ortner argue basf trapped endorse kaneb overvalued deaths netbacks\n",
      "Topic #79: south korea africa african rand programs korean rigs boycott panama\n",
      "Topic #80: said new meeting world price offer today farm told agreement\n",
      "Topic #81: gulf acres harvest area united states ships port shipping land\n",
      "Topic #82: tender canadian dealers oils vegetable bought dlrs cyclops dealer offer\n",
      "Topic #83: gold brazil said tons copper brazilian strike ounces ore mining\n",
      "Topic #84: french maize francs france community ecus licences soft row guarantees\n",
      "Topic #85: said dlrs company mln shares corp share pct stock group\n",
      "Topic #86: carrier servicing klm commonwealth denies paz robusta reschedule fortnightly constructed\n",
      "Topic #87: lord laidlaw loophole hague tanjug barnes flank ldc invitation long-standing\n",
      "Topic #88: exports coffee export soybeans ministers lawson calendar ico measure pound\n",
      "Topic #89: raises registrations three-for-two sulphur tanker tightening sweet kharg warplanes closed\n"
     ]
    }
   ],
   "source": [
    "# Show topis and feature names known by the model\n",
    "def print_topics(feature_names, n_top_words):\n",
    "    print(\"topics in LDA model:\")\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "n_top_words = 10\n",
    "print(\"the first {} feature names:\\n{}\".format(n_top_words, tf_feature_names[:n_top_words]))\n",
    "print_topics(tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents are sets of '**headline_text**' grouped by '**headline_category**' and **time**.<br>\n",
    "The first goal is to see how documents are grouped by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_topic(doc):\n",
    "    \"\"\" find the best topic for a document \"\"\"\n",
    "    if not isinstance(doc, list):\n",
    "        doc = [doc]\n",
    "    tokens = vectorizer.transform(doc)\n",
    "    estim = lda_model.transform(tokens)\n",
    "    # estim is a topic distribution, matrix[1, NUM_TOPICS]\n",
    "    idx = np.matrix(estim).argmax()\n",
    "    return (idx, estim[0, idx])  # index and max(distribution)\n",
    "\n",
    "def topic_name(idx):\n",
    "    \"\"\" return a topic name by index \"\"\"\n",
    "    if idx >= NUM_TOPICS:\n",
    "        raise ValueError(\"topic number {} exceed {}\".format(idx, NUM_TOPICS-1))\n",
    "    return 't{:02d}'.format(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fbc20ccb824f7094a221a0920d105a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='texts_by_topics', max=25046, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_topics = pd.DataFrame(df.publish_date)\n",
    "# add topics columns as 0\n",
    "for inum in range(NUM_TOPICS):\n",
    "    df_topics[topic_name(inum)] = 0.0\n",
    "df_topics['news_score'] = 0.0\n",
    "# get texts row by rows, define the best topic and make a sentiment analysis for a text\n",
    "# maxi = 100\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "for idx in tqdm.tqdm_notebook(df.index, desc='texts_by_topics'):\n",
    "    text = df.loc[idx, 'headline_text']\n",
    "    topic_num, _ = get_text_topic(text)\n",
    "    psc = sa.polarity_scores(text)\n",
    "    if psc['pos'] > psc['neg']:\n",
    "        df_topics.loc[idx, 'news_score'] = 1\n",
    "    elif psc['pos'] < psc['neg']:\n",
    "        df_topics.loc[idx, 'news_score'] = -1\n",
    "    df_topics.loc[idx, topic_name(topic_num)] = psc['pos'] - psc['neg']\n",
    "#     maxi -= 1\n",
    "#     if not maxi:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_topics includes estimations positive/neural/negative for texts, one estimation per row.<br/>\n",
    "Combine columns with few values to one 'other_topic' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-sufficient columns to merge in one: ['t01', 't03', 't11', 't12', 't14', 't15', 't17', 't18', 't21', 't24', 't25', 't30', 't35', 't39', 't42', 't44', 't46', 't47', 't49', 't51', 't53', 't57', 't59', 't60', 't63', 't65', 't66', 't68', 't70', 't73', 't76', 't78', 't87', 't89']\n"
     ]
    }
   ],
   "source": [
    "# how many columns have not enough data\n",
    "non_suff_cols = []\n",
    "for cidx in range(NUM_TOPICS):\n",
    "    col_name = topic_name(cidx)\n",
    "    col = df_topics[col_name]\n",
    "    nonz = 0\n",
    "    for elem in df_topics[topic_name(cidx)]:\n",
    "        if elem:\n",
    "            nonz += 1\n",
    "#     print(col_name, \":\", nonz)\n",
    "    if nonz < MIN_DOCS:\n",
    "        non_suff_cols.append(col_name)\n",
    "print(\"non-sufficient columns to merge in one:\", non_suff_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge non sufficient columns to 'other_topics'. Because non-zero value can be only in one position of row,\n",
    "it is possible to calc summ of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics['other_topic'] = 0\n",
    "for col_name in non_suff_cols:\n",
    "    df_topics.other_topic += df_topics[col_name]\n",
    "    \n",
    "df_topics2 = df_topics.drop(non_suff_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publish_date', 't00', 't01', 't02', 't03', 't04', 't05', 't06', 't07',\n",
       "       't08', 't09', 't10', 't11', 't12', 't13', 't14', 't15', 't16', 't17',\n",
       "       't18', 't19', 't20', 't21', 't22', 't23', 't24', 't25', 't26', 't27',\n",
       "       't28', 't29', 't30', 't31', 't32', 't33', 't34', 't35', 't36', 't37',\n",
       "       't38', 't39', 't40', 't41', 't42', 't43', 't44', 't45', 't46', 't47',\n",
       "       't48', 't49', 't50', 't51', 't52', 't53', 't54', 't55', 't56', 't57',\n",
       "       't58', 't59', 't60', 't61', 't62', 't63', 't64', 't65', 't66', 't67',\n",
       "       't68', 't69', 't70', 't71', 't72', 't73', 't74', 't75', 't76', 't77',\n",
       "       't78', 't79', 't80', 't81', 't82', 't83', 't84', 't85', 't86', 't87',\n",
       "       't88', 't89', 'news_score', 'other_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = df_topics2.groupby('publish_date').sum()\n",
    "# df_news.head(), df_news.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_csv('df_abc_news_score.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.6",
   "language": "python",
   "name": "ml3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
